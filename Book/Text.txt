







Chapter 1
Introduction









1.	Introduction
1.1	 Introduction
Facial key points detection is a computer technology being used in a variety of applications that identifies human faces in digital images. Facial key points detection also refers to the psychological process by which humans locate and attend to faces in a visual scene. Face detection can be regarded as a specific case of object-class detection. In object-class detection, the task is to find the locations and sizes of all objects in an image that belong to a given class. Detect facial keypoints is a critical element in face recognition. However, there is difficulty to catch keypoints on the face due to complex influences from original images, and there is no guidance to suitable algorithms. In this paper, we study different algorithms that can be applied to locate keyponits. Specifically: our framework (1)prepare the data for further investigation (2)Using PCA and LBP to process the data (3) Apply different algorithms to analysis data, including linear regression models, tree based model, neural network and convolutional neural network, etc. Finally we will give our conclusion and further research topic. A comprehensive set of experiments on dataset demonstrates the effectiveness of our framework. [Shenghao Shi, 15 Oct 2017, Machine Learning, Cornell University]

1.2	 Motivation
Detecting facial key points is a very challenging problem.  Facial features vary greatly from one individual to another, and even for a single individual, there is a large amount of variation due to 3D pose, size, position, viewing angle, and illumination conditions. Computer vision research has come a long way in addressing these difficulties, but there remain many opportunities for improvement. Recognizing faces is a very challenging problem in the field of image processing. The techniques presently being used are Biometric recognition (but Iris scanners are far too expensive), Eigenfaces(inaccurate with varying image factors like intensity, camera angles), line edgemaps. While facial features in images depend on a lot many conditions , faces can be recognised easily if we use the relevant keypoints and landmarks for identification. The unchanging ratios and distances between these mark the importance of this approach. [Ajay Sharma, 01 April 2015, Face detection: Artificial Intelligence, IIT Kanpur]

1.3	 Objective
The objective of this task is to predict key points positions on face images. Detection of facial keypoints is building block for many application in computer vision. Research has been done on this part but still there is hope for improvement. What really motivated me was that this problem works as the first steps for several applications, such as:
•	Tracking faces in images and video
•	Analyzing facial expressions
•	Detecting dysmorphic facial signs for medical diagnosis
•	Biometrics / face recognition

1.4	 Scope of the work
Importance of Face Recognition System as a Security Solution Face is considered as the most important part of human body. Research shows that even face can speak and it has different words for different emotions. It plays a very crucial role for interacting with people in the society. It conveys people’s identity, so it can be used as a key for security solutions in many organizations. Nowadays, face recognition system is getting increasing trend across the world for providing extremely safe and reliable security technology. It is gaining significant importance and attention by thousands of corporate and government organizations only because of its high level of security and reliability. Moreover, this system is providing vast benefits when compared to other biometric security solutions like palm print and finger print. As computation processing powers increases and large storage are available to store data, hence demand of it increases as it is used in several real-world applications.

1.5	 Outline of the thesis
In “Introduction”, the 1stchapter of the book contains the information about project motivation, the objective of the project and so on.
In “Literature Review”, the 2ndchapter of the book contains the information about Facial key points detection mechanism, Existing algorithms and its pros and cons, and a gentle overview of Machine learning, Deep learning and Convolutional Neural Network.
In “Existing system overview”, the 3rdchapter of the book contains the information about Existing system’s technical details and workflow, its pros and cons and features.
In “Proposed ML based facial key points detection system”, the 4thchapter of the book contains the information about Approach of proposed system, Diagram, Workflow and Merits.
In “Conclusion”, the 5thchapter of the book shows conclusion of this project.































Chapter 2
Literature Review









2.	Literature review
2.1	 Introduction
Face detection is a computer technology that is being applied for many different applications that require the identification of human faces in digital images or video. It can be regarded as a specific case of object-class detection, where the task is to find the locations and sizes of all objects in an image that belong to a given class. The technology is able to detect frontal or near-frontal faces in a photo, regardless of orientation, lighting conditions or skin color.

2.2	 How facial key points can be detected?
Face detection applications use algorithms that decides whether an image is a positive image also called face image or negative image also called non-face image. This is called a classifier. To classify a new image correctly, it is trained on hundreds of thousands of face and non-face images. This feature answers the question “Where are the faces in this picture?”. For each face detected, you get a complete analysis of key points also called landmarks around the eyes, eye brows, jaw, nose and mouth.

2.3	 Key points detection existing algorithms
OpenCV is a popular computer vision library started by Intel in 1999. The cross-platform library sets its focus on real-time image processing and includes patent-free implementations of the latest computer vision algorithms. OpenCV 2.3.1 now comes with a programming interface to C, C++, Python and Android. OpenCV 2.4 now comes with the very new Face Recognizer class for face recognition, so you can start experimenting with face recognition right away. The currently available algorithms are:
•	Eigenfaces
•	Fisherfaces
•	Local Binary Patterns Histograms

2.3.1	Pros
Some advantages of OpenCV face detection methods are:
•	Computationally simple and fast
•	Shorter training time
•	Low false positive rate
•	Better performance in offline learning system
2.3.2	Cons
Some disadvantages of OpenCV face detection methods are:
•	Not a knowledge-based system
•	Cannot be used in online learning system
•	Difficult to evolve

2.4	 Machine Learning, Deep Learning and Convolutional Neural Network
Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves. Machine learning is one of the most exciting technologies that one would have ever come across. As it is evident from the name, it gives the computer that which makes it more similar to humans: The ability to learn. Machine learning is actively being used today, perhaps in many more places than one would expect. Supervised learning: The computer is presented with example inputs and their desired outputs, given by a “teacher”, and the goal is to learn a general rule that maps inputs to outputs. The training process continues until the model achieves the desired level of accuracy on the training data. Some real-life examples are:
Image Classification: You train with images/labels. Then in the future you give a new image expecting that the computer will recognize the new object.
Market Prediction/Regression: You train the computer with historical market data and ask the computer to predict the new price in the future.
Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. It is used for clustering population in different groups. Unsupervised learning can be a goal in itself (discovering hidden patterns in data).
Clustering: You ask the computer to separate similar data into clusters, this is essential in research and science.
High Dimension Visualization: Use the computer to help us visualize high dimension data.
Generative Models: After a model captures the probability distribution of your input data, it will be able to generate more data. This can be very useful to make your classifier more robust.

Deep learning is a subset of machine learning in Artificial Intelligence (AI) that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as Deep Neural Learning or Deep Neural Network.
A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.
Deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. Deep learning is a key technology behind driverless cars, enabling them to recognize a stop sign, or to distinguish a pedestrian from a lamppost. It is the key to voice control in consumer devices like phones, tablets, TVs, and hands-free speakers. Deep learning is getting lots of attention lately and for good reason. It’s achieving results that were not possible before.
In deep learning, a computer model learns to perform classification tasks directly from images, text, or sound. Deep learning models can achieve state-of-the-art accuracy, sometimes exceeding human-level performance. Models are trained by using a large set of labeled data and neural network architectures that contain many layers.
Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction.

CNNs are powerful image processing, artificial intelligence (AI) that use deep learning to perform both generative and descriptive tasks, often using computer vision that includes image and video recognition, along with recommender systems and natural language processing.
Artificial Intelligence has been witnessing a monumental growth in bridging the gap between the capabilities of humans and machines. Researchers and enthusiasts alike, work on numerous aspects of the field to make amazing things happen. One of many such areas is the domain of Computer Vision.
The agenda for this field is to enable machines to view the world as humans do, perceive it in a similar manner and even use the knowledge for a multitude of tasks such as Image & Video recognition, Image Analysis & Classification, Media Recreation, Recommendation Systems, Natural Language Processing, etc. The advancements in Computer Vision with Deep Learning has been constructed and perfected with time, primarily over one particular algorithm — a Convolutional Neural Network.
A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters/characteristics.
The architecture of a ConvNet is analogous to that of the connectivity pattern of Neurons in the Human Brain and was inspired by the organization of the Visual Cortex. Individual neurons respond to stimuli only in a restricted region of the visual field known as the Receptive Field. A collection of such fields overlap to cover the entire visual area.
In deep learning, a convolutional neural network is a class of deep neural networks, most commonly applied to analyzing visual imagery. CNNs are regularized versions of multilayer perceptrons.

2.5	 Summary
In this chapter it is discussed where the system is being applied for. It is also shown that the system can be regarded as a specific case of object-class detection. Hundreds of thousands of face and non-face images data are fed to the system to classify new image correctly. OpenCV classifiers are existing solution to the system. Its pros and cons are also described in the chapter. Finally, a gentle overview to the Machine Learning, Deep Learning and Convolutional Neural Network is provided.


















Chapter 3
Existing system overview











3.	Existing system overview
3.1	 Introduction
OpenCV is a popular computer vision library started by Intel in 1999. The cross-platform library sets its focus on real-time image processing and includes patent-free implementations of the latest computer vision algorithms. OpenCV 2.3.1 now comes with a programming interface to C, C++, Python and Android. OpenCV 2.4 now comes with the very new Face Recognizer class for face recognition, so you can start experimenting with face recognition right away. The currently available algorithms are:
•	Eigenfaces
•	Fisherfaces
•	Local Binary Patterns Histograms

3.2	 OpenCV
Local Binary Patterns methodology is used in this project for its high accuracy. Local Binary Patterns methodology has its roots in 2D texture analysis. The basic idea of Local Binary Patterns is to summarize the local structure in an image by comparing each pixel with its neighbourhood. Take a pixel as centre and threshold its neighbours against. If the intensity of the centre pixel is greater-equal its neighbour, then denote it with 1 and 0 if not. You’ll end up with a binary number for each pixel, just like 11001111. So with 8 surrounding pixels, you’ll end up with 2^8 possible combinations, called Local Binary Patterns or sometimes referred to as LBP codes. The first LBP operator described in literature actually used a fixed 3 x 3 neighbourhood just like this:
 
A more formal description of the LBP operator can be given as:
 
, with   as central pixel with intensity  ; and   being the intensity of the neighbor pixel.   is the sign function defined as:
 
By definition, the LBP operator is robust against monotonic grey scale transformations. Dividing the LBP image into m local regions and extract a histogram from each. These histograms are called Local Binary Patterns Histograms.

3.3	 Workflow
Face Recognition process is about three steps:
•	Prepare Training Data: Read training images for each person/subject along with their labels, detect faces from each image and assign each detected face an integer label of the person it belongs.
•	Train Face Recognizer: Train OpenCV's LBPH recognizer by feeding it the data we prepared in step 1.
•	Prediction: Introduce some test images to face recognizer and see if it predicts them correctly.

3.4	 Result table
3.5	 Pros and Cons
Some advantages of OpenCV face detection methods are:
•	Computationally simple and fast
•	Shorter training time
•	Low false positive rate
•	Better performance in offline learning system
Some disadvantages of OpenCV face detection methods are:
•	Not a knowledge-based system
•	Cannot be used in online learning system
•	Difficult to evolve

3.6	 Summary
In this chapter it is discussed what OpenCV is. It is also shown that what methods of face detection are offered by OpenCV and how to use that methods. OpenCV's technical details, to be specific how Local Binary Pattern method works are discussed here. It also depicts workflow of OpenCV face detection and its pros and cons are also described in the chapter.



















Chapter 4
Proposed ML based facial key points detection system









4.	Proposed Machine Learning based facial key points detection system
4.1	 Introduction
In this proposed system, the combined knowledge of computer vision techniques and deep learning architectures will be applied to build a facial keypoint detection system. Facial keypoints include points around the eyes, nose, and mouth on a face and are used in many applications. This system has several applications including facial tracking, facial pose recognition, facial filters, and emotion recognition. The final system should be able to look at any image, detect faces, and predict the locations of facial keypoints on each face.

4.2	 Approach of the proposed system
4.2.1	Diagram
4.2.2	Description
In the proposed system, analysis of the face detection problem is performed at first. It includes data cleaning, data visualization and features extraction. Then appropriate Machine Learning algorithm is applied on training data such as Logistic regression, Deep Learning, Convolutional Neural Network etc. After that, a model can be obtained and test data are applied on that model. Result are obtained and then error analysis of the model is performed. If error rate is greater than a threshold value then changes to model are required else the model is deployed. This process is repitative.

4.3	 Workflow : User perspective
4.4	 Features
Some features of the proposed system are:
•	This system is a knowledge-based system
•	It can be used in online learning system
•	It is easy to evolve the model
•	It is possible to automate the learning system

CNNs, like neural networks, are made up of neurons with learnable weights and biases. Each neuron receives several inputs, takes a weighted sum over them, pass it through an activation function and responds with an output. The whole network has a loss function and all the tips and tricks that we developed for neural networks still apply on CNNs.


CNNs operate over Volumes
Unlike neural networks, where the input is a vector, here the input is a multi-channeled image (3 channeled in this case). There are other differences that we will talk about in a while. Before we go any deeper, we have to understand what convolution means. Example of a RGB image

Convolution

2. Convolving an image with a filter
We take the 5*5*3 filter and slide it over the complete image and along the way take the dot product between the filter and chunks of the input image.

3. How convolution looks
For every dot product taken, the result is a scalar. when we convolve the complete image with the filter we will get 28*28 unique positions where the filter can be put on the image.

4. This!
I leave it upon you to figure out how the ‘28’ comes. (Hint: There are 28*28  )
Now, if we back to CNNs the convolution layer is the main building block of a convolutional neural network.

5. Convolution Layer
The convolution layer comprises of a set of independent filters. In this example there are 6 independent filters. Each filter is independently convolved with the image and we end up with 6 feature maps of shape 28*28*1.
Suppose we have a number of convolution layers in sequence. What happens then?

6. Convolution Layers in sequence
All these filters are initialized randomly and become our parameters which will be learned by the network subsequently.
An example of a trained network of face images is look like below.

7. Filters in a trained network
Take a look at the filters in the very first layer. These are our 5*5*3 filters. Through back propagation, they have tuned themselves to become blobs of coloured pieces and edges. As we go deeper to other convolution layers, the filters are doing dot products to the input of the previous convolution layers. So, they are taking the smaller coloured pieces or edges and making larger pieces out of them.
Take a look and imagine the 28*28*1 grid as a grid of 28*28 neurons. For a particular feature map the output received on convolving the image with a particular filter is called a feature map, each neuron is connected only to a small chunk of the input image and all the neurons have the same connection weights. So again coming back to the differences between CNN and a neural network.
------
CNNs parameter and connectivity
Parameter sharing is sharing of weights by all neurons in a particular feature map.
Local connectivity is the concept of each neural connected only to a subset of the input image unlike a neural network where all the neurons are fully connected.
This helps to reduce the number of parameters in the whole system and makes the computation more efficient.


Pooling Layers
A pooling layer is another building block of a CNN.

Pooling
Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network. Pooling layer operates on each feature map independently.
The most common approach used in pooling is max pooling.

Max Pooling
Typical Architecture of a CNN

Typical architecture of CNN
We have already discussed about convolution layers denoted by CONV and pooling layers denoted by POOL. RELU is just a non linearity which is applied similar to neural networks.
The FC is the fully connected layer of neurons at the end of CNN. Neurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks and work in a similar way.


4.5	 Merits of the system
Some merits of the proposed system are:
•	Detect facial key points with high accuracy
•	Easy to used in time series problem
•	Low false positive rate
•	Improved computing performance with short training time

4.6	 Required tools
Required tools for the proposed system are:
•	Python 3.5
•	IDE
•	Numpy
•	Matplotlib
•	Pandas
•	Seaborn
•	Tensorflow
•	Keras

4.7	 Summary
In this chapter proposed system is discussed in details. A diagram is also provided that depicts how the proposed system will work and its description provided as well. A user view workflow, features and merits of the proposed system is also given. Finally, required tools for the proposed system is also mentioned.





















Chapter 5
Conclusion









5.	Conclusion
5.1	 Conclusion
Detecing facial keypoints is a very challenging problem. Facial features vary greatly from one individual to another due to position, viewing angle, and illumination conditions. Computer vision research has come a long way in addressing these difficulties, but there remain many opportunities for improvement. This proposed system will provide high accuracy performance to detect facial key points using latest trending technologies.









Each predicted keypoint is specified by an (x,y) real-valued pair in the space of pixel indices. There are 15 keypoints, which represent the following elements of the face:

left_eye_center, right_eye_center, left_eye_inner_corner, left_eye_outer_corner, right_eye_inner_corner, right_eye_outer_corner, left_eyebrow_inner_end, left_eyebrow_outer_end, right_eyebrow_inner_end, right_eyebrow_outer_end, nose_tip, mouth_left_corner, mouth_right_corner, mouth_center_top_lip, mouth_center_bottom_lip

Left and right here refers to the point of view of the subject.

In some examples, some of the target keypoint positions are misssing (encoded as missing entries in the csv, i.e., with nothing between two commas).

The input image is given in the last field of the data files, and consists of a list of pixels (ordered by row), as integers in (0,255). The images are 96x96 pixels.

///////////////
The sequential API allows you to create models layer-by-layer for most problems. It is limited in that it does not allow you to create models that share layers or have multiple inputs or outputs.



\\\\\\\\\\\\\\\\\\\\\\\\\
The Jupyter Notebook is an incredibly powerful tool for interactively developing and presenting data science projects. This article will walk you through how to set up Jupyter Notebooks on your local machine and how to start using it to do data science projects.
Firstly, a notebook integrates code and its output into a single document that combines visualizations, narrative text, mathematical equations, and other rich media. This intuitive workflow promotes iterative and rapid development, making notebooks an increasingly popular choice at the heart of contemporary data science, analysis, and increasingly science at large.
On Windows, you can run Jupyter via the shortcut Anaconda adds to your start menu, which will open a new tab in your default web browser that should look something like the following screenshot.

TensorFlow is a Python-friendly open source library for numerical computation that makes machine learning faster and easier.
Machine learning is a complex discipline. But implementing machine learning models is far less daunting and difficult than it used to be, thanks to machine learning frameworks—such as Google’s TensorFlow—that ease the process of acquiring data, training models, serving predictions, and refining future results.
Created by the Google Brain team, TensorFlow is an open source library for numerical computation and large-scale machine learning. TensorFlow bundles together a slew of machine learning and deep learning (aka neural networking) models and algorithms and makes them useful by way of a common metaphor. It uses Python to provide a convenient front-end API for building applications with the framework, while executing those applications in high-performance C++.